{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b84ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "# Add parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "import data_generation\n",
    "importlib.reload(data_generation)\n",
    "from data_generation import collect_businesses_data\n",
    "from data_generation import is_meaningful_description\n",
    "from data_generation import test_pipeline\n",
    "from data_generation import process_collected_data\n",
    "from data_generation import analyze_fallback_patterns\n",
    "from data_generation import load_existing_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors_to_collect = [\n",
    "    \"restaurant\",\n",
    "    \"retail store\", \n",
    "    \"law firm\",\n",
    "    \"beauty salon\",\n",
    "    \"gym\",\n",
    "    \"nonprofit organization\",\n",
    "    \"medical clinic\",\n",
    "    \"nightclub\",\n",
    "    \"café / bakery\",\n",
    "    \"hotel / motel\",\n",
    "    \"real estate agency\",\n",
    "    \"construction / home services\",\n",
    "    \"cleaning service\",\n",
    "    \"veterinary clinic\",\n",
    "    \"dentist\",\n",
    "    \"physiotherapy clinic\",\n",
    "    \"entertainment venue (cinema, bowling, etc.)\",\n",
    "    \"transportation / taxi service\",\n",
    "    \"accounting firm\",\n",
    "    \"insurance broker\",\n",
    "    \"financial advisory service\",\n",
    "    \"IT services / software consultancy\",\n",
    "    \"computer / phone repair shop\",\n",
    "    \"coworking space\",\n",
    "    \"education / tutoring center\",\n",
    "    \"language school\",\n",
    "    \"training institute\"\n",
    "]\n",
    "\n",
    "cities = [\"New York, USA\", \"Los Angeles, USA\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8263f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Starting business data collection...\")\n",
    "print(f\"Will collect up to 50 businesses per sector per city\")\n",
    "print(f\"Sectors: {len(sectors_to_collect)}\")\n",
    "print(f\"Cities: {len(cities)}\")\n",
    "print(f\"Maximum total businesses: {len(sectors_to_collect) * len(cities) * 50}\")\n",
    "\n",
    "# Ask for confirmation before starting\n",
    "response = input(\"\\nDo you want to proceed? This may take a while... (y/n): \")\n",
    "if response.lower() in ['y', 'yes']:\n",
    "    data = collect_businesses_data()\n",
    "    print(\"\\nCollection completed!\")\n",
    "else:\n",
    "    print(\"Collection cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea92ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Input and output file paths\n",
    "raw_file = \"../data/all_businesses_data.json\"\n",
    "clean_file = \"../data/all_businesses_data_clean.json\"\n",
    "\n",
    "# Load raw JSON\n",
    "with open(raw_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# Extract raw businesses\n",
    "businesses = raw_data.get(\"businesses\", [])\n",
    "\n",
    "# Filter + clean businesses\n",
    "cleaned_businesses = []\n",
    "for b in businesses:\n",
    "    desc = b.get(\"scraped_description\", \"\")\n",
    "    website = b.get(\"website\")\n",
    "    \n",
    "    # Skip if no website\n",
    "    if not website:\n",
    "        continue\n",
    "\n",
    "    # Skip businesses with scraping errors or empty text\n",
    "    if desc.startswith(\"Could not access website\") or desc.startswith(\"An error occurred during scraping\"):\n",
    "        continue\n",
    "    if desc.strip() in [\"\", \"No description found on the website.\"]:\n",
    "        continue\n",
    "\n",
    "    if not is_meaningful_description(desc):\n",
    "        continue\n",
    "    \n",
    "    cleaned_entry = {\n",
    "        \"fsq_place_id\": b.get(\"fsq_place_id\"),\n",
    "        \"name\": b.get(\"name\"),\n",
    "        \"sector\": b.get(\"sector\"),\n",
    "        \"city\": b.get(\"city\"),\n",
    "        \"website\": b.get(\"website\"),\n",
    "        \"scraped_description\": desc,\n",
    "        \"address\": b.get(\"address\"),\n",
    "        # Keep only category names\n",
    "        \"categories\": [c.get(\"name\") for c in b.get(\"categories\", []) if \"name\" in c]\n",
    "    }\n",
    "    cleaned_businesses.append(cleaned_entry)\n",
    "\n",
    "# ---- Rebuild metadata ----\n",
    "collection_stats = {\n",
    "    \"total_collected\": len(cleaned_businesses),\n",
    "    \"by_sector\": defaultdict(lambda: {\"total\": 0, \"by_city\": defaultdict(int)}),\n",
    "    \"by_city\": defaultdict(int),\n",
    "    \"errors\": []  # all filtered out, so we don't carry them\n",
    "}\n",
    "\n",
    "for b in cleaned_businesses:\n",
    "    sector = b[\"sector\"]\n",
    "    city = b[\"city\"]\n",
    "    \n",
    "    collection_stats[\"total_collected\"] += 0  # already counted\n",
    "    collection_stats[\"by_sector\"][sector][\"total\"] += 1\n",
    "    collection_stats[\"by_sector\"][sector][\"by_city\"][city] += 1\n",
    "    collection_stats[\"by_city\"][city] += 1\n",
    "\n",
    "# Convert defaultdicts back to normal dicts for JSON\n",
    "def deep_convert(d):\n",
    "    if isinstance(d, defaultdict):\n",
    "        d = {k: deep_convert(v) for k, v in d.items()}\n",
    "    elif isinstance(d, dict):\n",
    "        d = {k: deep_convert(v) for k, v in d.items()}\n",
    "    return d\n",
    "\n",
    "collection_stats = deep_convert(collection_stats)\n",
    "\n",
    "clean_output_data = {\n",
    "    \"collection_metadata\": {\n",
    "        \"timestamp\": raw_data.get(\"collection_metadata\", {}).get(\"timestamp\"),\n",
    "        \"total_businesses\": len(cleaned_businesses),\n",
    "        \"sectors_collected\": raw_data.get(\"collection_metadata\", {}).get(\"sectors_collected\", []),\n",
    "        \"cities_collected\": raw_data.get(\"collection_metadata\", {}).get(\"cities_collected\", []),\n",
    "        \"stats\": collection_stats\n",
    "    },\n",
    "    \"businesses\": cleaned_businesses\n",
    "}\n",
    "\n",
    "# Save clean version\n",
    "with open(clean_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(clean_output_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Clean data saved to: {clean_file}\")\n",
    "print(f\"Total businesses before filtering: {len(businesses)}\")\n",
    "print(f\"Total businesses after filtering: {len(cleaned_businesses)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d77c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_business = {\n",
    "    \"fsq_place_id\": \"test1\",\n",
    "    \"name\": \"Sunrise Organic Coffee\",\n",
    "    \"sector\": \"café / bakery\",\n",
    "    \"city\": \"New York, USA\",\n",
    "    \"scraped_description\": \"Welcome to our cozy coffee shop where we serve the finest organic coffee beans sourced directly from sustainable farms. We also offer fresh pastries baked daily and provide a comfortable space for work or relaxation.\"\n",
    "}\n",
    "\n",
    "test_pipeline(test_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../data/all_businesses_data_clean.json\"\n",
    "output_file = \"../data/all_businesses_descriptions_and_domains.json\"\n",
    "\n",
    "processed_collected_data = process_collected_data(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file = \"temp_data.json\"\n",
    "input_file = \"../data/all_businesses_data_clean.json\"\n",
    "output_file = \"../data/all_businesses_descriptions_and_domains.json\"\n",
    "\n",
    "# First, analyze what's in the temp file\n",
    "print(\"Analyzing current temp file...\")\n",
    "analyze_fallback_patterns(temp_file)\n",
    "\n",
    "# Then resume processing\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING RESUME PROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "processed_collected_data = process_collected_data(\n",
    "    input_file=input_file,\n",
    "    output_file=output_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966833f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(temp_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    data = data[\"results\"]\n",
    "\n",
    "seen = set()\n",
    "duplicates = []\n",
    "\n",
    "for entry in data:\n",
    "    business_id = entry[\"business\"][\"fsq_place_id\"]\n",
    "    if business_id in seen:\n",
    "        duplicates.append(business_id)\n",
    "    else:\n",
    "        seen.add(business_id)\n",
    "\n",
    "if duplicates:\n",
    "    print(\"❌ Found duplicates:\", duplicates)\n",
    "    print(f\"Total duplicates found: {len(duplicates)}\")\n",
    "else:\n",
    "    print(\"✅ No duplicates found!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
